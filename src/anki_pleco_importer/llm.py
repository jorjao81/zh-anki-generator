"""LLM-based field generators for Anki cards."""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
from pydantic import BaseModel


class TokenUsage(BaseModel):
    """Token usage information from an LLM API call."""

    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    cost_usd: float = 0.0


class FieldGenerationResult(BaseModel):
    """Structured results for fields generated by an LLM."""

    structural_decomposition: Optional[str] = None
    etymology: Optional[str] = None
    token_usage: Optional[TokenUsage] = None


class FieldGenerator(ABC):
    """Interface for generating additional Anki card fields."""

    @abstractmethod
    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        """Generate fields for the given Chinese text."""
        raise NotImplementedError


class GptFieldGenerator(FieldGenerator):
    """Generate fields using an OpenAI GPT model."""

    # GPT-5 pricing per 1M tokens (August 2025 official pricing)
    PRICING = {
        "gpt-5": {"input": 1.25, "output": 10.00, "cached_input": 0.125},
        "gpt-5-mini": {"input": 0.25, "output": 2.00},
        "gpt-5-nano": {"input": 0.05, "output": 0.40},
    }

    def __init__(
        self,
        model: str,
        api_key: Optional[str] = None,
        prompt_path: Optional[str] = None,
        thinking: Optional[Dict[str, Any]] = None,
        reasoning_effort: str = "medium",
        temperature: Optional[float] = None,
        use_web_search: bool = False,
    ) -> None:
        from openai import OpenAI
        from pathlib import Path

        self.client = OpenAI(api_key=api_key) if api_key else OpenAI()
        self.model = model
        self.thinking = thinking
        self.reasoning_effort = reasoning_effort
        self.temperature = temperature
        self.use_web_search = use_web_search
        
        # Load both single and multi-character prompts
        self.single_char_prompt = ""
        self.multi_char_prompt = ""
        
        if prompt_path:
            prompt_path_obj = Path(prompt_path)
            
            # Load single character prompt (the default one)
            with open(prompt_path, "r", encoding="utf-8") as f:
                self.single_char_prompt = f.read()

            # Load multi-character prompt
            multi_char_path = prompt_path_obj.parent / "prompt_multi_char.md"
            if multi_char_path.exists():
                with open(multi_char_path, "r", encoding="utf-8") as f:
                    self.multi_char_prompt = f.read()
            else:
                # Fallback to single char prompt if multi-char doesn't exist
                self.multi_char_prompt = self.single_char_prompt

            # Load examples from the appropriate examples directories
            single_examples_dir = prompt_path_obj.parent / "examples_single_char"
            multi_examples_dir = prompt_path_obj.parent / "examples_multi_char"
            
            if single_examples_dir.exists():
                self.single_char_prompt = self._load_prompt_with_examples(self.single_char_prompt, single_examples_dir)
            
            if multi_examples_dir.exists():
                self.multi_char_prompt = self._load_prompt_with_examples(self.multi_char_prompt, multi_examples_dir)
            
            # Fallback to shared examples directory if separate ones don't exist
            shared_examples_dir = prompt_path_obj.parent / "examples"
            if shared_examples_dir.exists() and not single_examples_dir.exists() and not multi_examples_dir.exists():
                self.single_char_prompt = self._load_prompt_with_examples(self.single_char_prompt, shared_examples_dir)
                self.multi_char_prompt = self._load_prompt_with_examples(self.multi_char_prompt, shared_examples_dir)

    def _load_prompt_with_examples(self, base_prompt: str, examples_dir) -> str:
        """Load examples from the examples directory and incorporate them into the prompt."""
        import glob
        import os

        examples_text = "\n\nHere are examples of the expected output format:\n\n"
        
        # Determine if this is for single or multi-character examples
        is_single_char = "single_char" in str(examples_dir)
        is_multi_char = "multi_char" in str(examples_dir)

        # Load all structural decomposition examples
        structural_files = glob.glob(str(examples_dir / "structural_decomposition*.html"))
        structural_files.sort()  # Ensure consistent ordering
        
        for i, structural_path in enumerate(structural_files, 1):
            if os.path.getsize(structural_path) > 0:  # Skip empty files
                with open(structural_path, "r", encoding="utf-8") as f:
                    structural_content = f.read().strip()
                if structural_content:
                    if is_single_char:
                        example_name = "忆" if i == 1 else f"single char example {i}"
                    elif is_multi_char:
                        example_name = "学校" if i == 1 else f"multi char example {i}"
                    else:
                        example_name = "忆" if i == 1 else f"example {i}"  # fallback for shared examples
                    examples_text += f"**Example structural_decomposition_html for {example_name}:**\n```html\n{structural_content}\n```\n\n"

        # Load all etymology examples
        etymology_files = glob.glob(str(examples_dir / "etymology*.html"))
        etymology_files.sort()  # Ensure consistent ordering
        
        for i, etymology_path in enumerate(etymology_files, 1):
            if os.path.getsize(etymology_path) > 0:  # Skip empty files
                with open(etymology_path, "r", encoding="utf-8") as f:
                    etymology_content = f.read().strip()
                if etymology_content:
                    if is_single_char:
                        example_name = "忆" if i == 1 else f"single char example {i}"
                    elif is_multi_char:
                        example_name = "学校" if i == 1 else f"multi char example {i}"
                    else:
                        example_name = "忆" if i == 1 else f"example {i}"  # fallback for shared examples
                    examples_text += f"**Example etymology_html for {example_name}:**\n```html\n{etymology_content}\n```\n\n"

        examples_text += "Please follow these formats exactly, using the same HTML structure and CSS classes.\n"

        return base_prompt + examples_text

    def _calculate_cost(self, usage_dict: dict) -> float:
        """Calculate cost in USD based on token usage."""
        if self.model not in self.PRICING:
            return 0.0

        pricing = self.PRICING[self.model]
        # OpenAI Responses API uses 'input_tokens' and 'output_tokens'
        prompt_tokens = usage_dict.get("input_tokens", usage_dict.get("prompt_tokens", 0))
        completion_tokens = usage_dict.get("output_tokens", usage_dict.get("completion_tokens", 0))

        # Cost per 1M tokens, so divide by 1,000,000
        input_cost = (prompt_tokens * pricing["input"]) / 1_000_000
        output_cost = (completion_tokens * pricing["output"]) / 1_000_000

        return input_cost + output_cost

    def _is_single_character(self, chinese: str) -> bool:
        """Check if the Chinese text is a single character."""
        import re
        # Remove any non-Chinese characters and check if exactly one character remains
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', chinese)
        return len(chinese_chars) == 1

    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        import json

        # Choose appropriate prompt based on character count
        is_single_char = self._is_single_character(chinese)
        prompt_to_use = self.single_char_prompt if is_single_char else self.multi_char_prompt
        
        # Create input messages for Responses API
        input_messages = [
            {"role": "system", "content": prompt_to_use},
            {
                "role": "user",
                "content": json.dumps({"character": chinese, "pinyin": pinyin}, ensure_ascii=False),
            },
        ]
        
        kwargs: Dict[str, Any] = {
            "model": self.model,
            "input": input_messages,
        }
        
        if self.temperature is not None:
            kwargs["temperature"] = self.temperature
            
        # Add web search tool if requested
        if self.use_web_search:
            kwargs["tools"] = [{"type": "web_search_preview"}]

        response = self.client.responses.create(**kwargs)
        content = response.output_text
        data = json.loads(content)

        # Extract token usage and calculate cost
        usage_dict = response.usage.dict() if response.usage else {}
        cost = self._calculate_cost(usage_dict)

        # OpenAI Responses API uses 'input_tokens' and 'output_tokens'
        prompt_tokens = usage_dict.get("input_tokens", usage_dict.get("prompt_tokens", 0))
        completion_tokens = usage_dict.get("output_tokens", usage_dict.get("completion_tokens", 0))

        token_usage = TokenUsage(
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=usage_dict.get("total_tokens", 0),
            cost_usd=cost,
        )

        return FieldGenerationResult(
            structural_decomposition=data.get("structural_decomposition_html"),
            etymology=data.get("etymology_html"),
            token_usage=token_usage,
        )


class GeminiFieldGenerator(FieldGenerator):
    """Generate fields using Google Gemini model."""

    # Gemini 2.5 pricing per 1M tokens (2025 pricing)
    PRICING = {
        "gemini-2.5-pro": {"input": 1.25, "output": 10.00, "cached_input": 0.3125},
        "gemini-2.5-flash": {"input": 0.30, "output": 2.50, "cached_input": 0.075},
        "gemini-2.5-flash-lite": {"input": 0.10, "output": 0.40, "cached_input": 0.025},
    }

    def __init__(
        self,
        model: str,
        api_key: Optional[str] = None,
        prompt_path: Optional[str] = None,
        temperature: Optional[float] = None,
    ) -> None:
        import google.generativeai as genai
        
        if api_key:
            genai.configure(api_key=api_key)
        
        self.model = model
        self.temperature = temperature
        
        # Load both single and multi-character prompts
        self.single_char_prompt = ""
        self.multi_char_prompt = ""
        
        if prompt_path:
            from pathlib import Path
            prompt_path_obj = Path(prompt_path)
            
            # Load single character prompt (the default one)
            with open(prompt_path, "r", encoding="utf-8") as f:
                self.single_char_prompt = f.read()

            # Load multi-character prompt
            multi_char_path = prompt_path_obj.parent / "prompt_multi_char.md"
            if multi_char_path.exists():
                with open(multi_char_path, "r", encoding="utf-8") as f:
                    self.multi_char_prompt = f.read()
            else:
                # Fallback to single char prompt if multi-char doesn't exist
                self.multi_char_prompt = self.single_char_prompt

            # Load examples from the appropriate examples directories
            single_examples_dir = prompt_path_obj.parent / "examples_single_char"
            multi_examples_dir = prompt_path_obj.parent / "examples_multi_char"
            
            if single_examples_dir.exists():
                self.single_char_prompt = self._load_prompt_with_examples(self.single_char_prompt, single_examples_dir)
            
            if multi_examples_dir.exists():
                self.multi_char_prompt = self._load_prompt_with_examples(self.multi_char_prompt, multi_examples_dir)
            
            # Fallback to shared examples directory if separate ones don't exist
            shared_examples_dir = prompt_path_obj.parent / "examples"
            if shared_examples_dir.exists() and not single_examples_dir.exists() and not multi_examples_dir.exists():
                self.single_char_prompt = self._load_prompt_with_examples(self.single_char_prompt, shared_examples_dir)
                self.multi_char_prompt = self._load_prompt_with_examples(self.multi_char_prompt, shared_examples_dir)

        # Initialize the model
        self.genai_model = genai.GenerativeModel(model)

    def _load_prompt_with_examples(self, base_prompt: str, examples_dir) -> str:
        """Load examples from the examples directory and incorporate them into the prompt."""
        import glob
        import os

        examples_text = "\n\nHere are examples of the expected output format:\n\n"
        
        # Determine if this is for single or multi-character examples
        is_single_char = "single_char" in str(examples_dir)
        is_multi_char = "multi_char" in str(examples_dir)

        # Load all structural decomposition examples
        structural_files = glob.glob(str(examples_dir / "structural_decomposition*.html"))
        structural_files.sort()  # Ensure consistent ordering
        
        for i, structural_path in enumerate(structural_files, 1):
            if os.path.getsize(structural_path) > 0:  # Skip empty files
                with open(structural_path, "r", encoding="utf-8") as f:
                    structural_content = f.read().strip()
                if structural_content:
                    if is_single_char:
                        example_name = "忆" if i == 1 else f"single char example {i}"
                    elif is_multi_char:
                        example_name = "学校" if i == 1 else f"multi char example {i}"
                    else:
                        example_name = "忆" if i == 1 else f"example {i}"  # fallback for shared examples
                    examples_text += f"**Example structural_decomposition_html for {example_name}:**\n```html\n{structural_content}\n```\n\n"

        # Load all etymology examples
        etymology_files = glob.glob(str(examples_dir / "etymology*.html"))
        etymology_files.sort()  # Ensure consistent ordering
        
        for i, etymology_path in enumerate(etymology_files, 1):
            if os.path.getsize(etymology_path) > 0:  # Skip empty files
                with open(etymology_path, "r", encoding="utf-8") as f:
                    etymology_content = f.read().strip()
                if etymology_content:
                    if is_single_char:
                        example_name = "忆" if i == 1 else f"single char example {i}"
                    elif is_multi_char:
                        example_name = "学校" if i == 1 else f"multi char example {i}"
                    else:
                        example_name = "忆" if i == 1 else f"example {i}"  # fallback for shared examples
                    examples_text += f"**Example etymology_html for {example_name}:**\n```html\n{etymology_content}\n```\n\n"

        examples_text += "Please follow these formats exactly, using the same HTML structure and CSS classes.\n"

        return base_prompt + examples_text

    def _calculate_cost(self, usage_dict: dict) -> float:
        """Calculate cost in USD based on token usage."""
        if self.model not in self.PRICING:
            return 0.0

        pricing = self.PRICING[self.model]
        # Gemini API uses 'prompt_token_count' and 'candidates_token_count'
        prompt_tokens = usage_dict.get("prompt_token_count", 0)
        completion_tokens = usage_dict.get("candidates_token_count", 0)

        # Cost per 1M tokens, so divide by 1,000,000
        input_cost = (prompt_tokens * pricing["input"]) / 1_000_000
        output_cost = (completion_tokens * pricing["output"]) / 1_000_000

        return input_cost + output_cost

    def _is_single_character(self, chinese: str) -> bool:
        """Check if the Chinese text is a single character."""
        import re
        # Remove any non-Chinese characters and check if exactly one character remains
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', chinese)
        return len(chinese_chars) == 1

    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        import json

        # Choose appropriate prompt based on character count
        is_single_char = self._is_single_character(chinese)
        prompt_to_use = self.single_char_prompt if is_single_char else self.multi_char_prompt

        # Create the prompt with character and pinyin
        user_input = json.dumps({"character": chinese, "pinyin": pinyin}, ensure_ascii=False)
        full_prompt = f"{prompt_to_use}\n\n{user_input}"

        # Configure generation parameters
        generation_config = {}
        if self.temperature is not None:
            generation_config["temperature"] = self.temperature
        
        # Set response format to JSON
        generation_config["response_mime_type"] = "application/json"

        try:
            response = self.genai_model.generate_content(
                full_prompt,
                generation_config=generation_config
            )
            
            content = response.text
            data = json.loads(content)

            # Extract token usage and calculate cost
            usage_dict = {}
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                usage_dict = {
                    "prompt_token_count": response.usage_metadata.prompt_token_count,
                    "candidates_token_count": response.usage_metadata.candidates_token_count,
                    "total_token_count": response.usage_metadata.total_token_count,
                }
            
            cost = self._calculate_cost(usage_dict)

            token_usage = TokenUsage(
                prompt_tokens=usage_dict.get("prompt_token_count", 0),
                completion_tokens=usage_dict.get("candidates_token_count", 0),
                total_tokens=usage_dict.get("total_token_count", 0),
                cost_usd=cost,
            )

            return FieldGenerationResult(
                structural_decomposition=data.get("structural_decomposition_html"),
                etymology=data.get("etymology_html"),
                token_usage=token_usage,
            )

        except Exception as e:
            # Return empty result with error info in case of failure
            return FieldGenerationResult(
                token_usage=TokenUsage(cost_usd=0.0)
            )
