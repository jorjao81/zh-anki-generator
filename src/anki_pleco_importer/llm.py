"""LLM-based field generators for Anki cards."""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
from pydantic import BaseModel


class TokenUsage(BaseModel):
    """Token usage information from an LLM API call."""

    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    cost_usd: float = 0.0


class FieldGenerationResult(BaseModel):
    """Structured results for fields generated by an LLM."""

    structural_decomposition: Optional[str] = None
    etymology: Optional[str] = None
    token_usage: Optional[TokenUsage] = None


class FieldGenerator(ABC):
    """Interface for generating additional Anki card fields."""

    @abstractmethod
    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        """Generate fields for the given Chinese text."""
        raise NotImplementedError


class GptFieldGenerator(FieldGenerator):
    """Generate fields using an OpenAI GPT model."""

    # GPT-5 pricing per 1M tokens (August 2025 official pricing)
    PRICING = {
        "gpt-5": {"input": 1.25, "output": 10.00, "cached_input": 0.125},
        "gpt-5-mini": {"input": 0.25, "output": 2.00},
        "gpt-5-nano": {"input": 0.05, "output": 0.40},
    }

    def __init__(
        self,
        model: str,
        api_key: Optional[str] = None,
        prompt_path: Optional[str] = None,
        thinking: Optional[Dict[str, Any]] = None,
        reasoning_effort: str = "medium",
        temperature: Optional[float] = None,
        use_web_search: bool = False,
    ) -> None:
        from openai import OpenAI

        self.client = OpenAI(api_key=api_key) if api_key else OpenAI()
        self.model = model
        self.thinking = thinking
        self.reasoning_effort = reasoning_effort
        self.temperature = temperature
        self.use_web_search = use_web_search
        self.prompt = ""
        if prompt_path:
            with open(prompt_path, "r", encoding="utf-8") as f:
                self.prompt = f.read()

            # Load examples from the examples directory if it exists
            from pathlib import Path

            examples_dir = Path(prompt_path).parent / "examples"
            if examples_dir.exists():
                self.prompt = self._load_prompt_with_examples(self.prompt, examples_dir)

    def _load_prompt_with_examples(self, base_prompt: str, examples_dir) -> str:
        """Load examples from the examples directory and incorporate them into the prompt."""
        import glob
        import os

        examples_text = "\n\nHere are examples of the expected output format:\n\n"

        # Load all structural decomposition examples
        structural_files = glob.glob(str(examples_dir / "structural_decomposition*.html"))
        structural_files.sort()  # Ensure consistent ordering
        
        for i, structural_path in enumerate(structural_files, 1):
            if os.path.getsize(structural_path) > 0:  # Skip empty files
                with open(structural_path, "r", encoding="utf-8") as f:
                    structural_content = f.read().strip()
                if structural_content:
                    example_name = "忆" if i == 1 else f"example {i}"
                    examples_text += f"**Example structural_decomposition_html for {example_name}:**\n```html\n{structural_content}\n```\n\n"

        # Load all etymology examples
        etymology_files = glob.glob(str(examples_dir / "etymology*.html"))
        etymology_files.sort()  # Ensure consistent ordering
        
        for i, etymology_path in enumerate(etymology_files, 1):
            if os.path.getsize(etymology_path) > 0:  # Skip empty files
                with open(etymology_path, "r", encoding="utf-8") as f:
                    etymology_content = f.read().strip()
                if etymology_content:
                    example_name = "忆" if i == 1 else f"example {i}"
                    examples_text += f"**Example etymology_html for {example_name}:**\n```html\n{etymology_content}\n```\n\n"

        examples_text += "Please follow these formats exactly, using the same HTML structure and CSS classes.\n"

        return base_prompt + examples_text

    def _calculate_cost(self, usage_dict: dict) -> float:
        """Calculate cost in USD based on token usage."""
        if self.model not in self.PRICING:
            return 0.0

        pricing = self.PRICING[self.model]
        # OpenAI Responses API uses 'input_tokens' and 'output_tokens'
        prompt_tokens = usage_dict.get("input_tokens", usage_dict.get("prompt_tokens", 0))
        completion_tokens = usage_dict.get("output_tokens", usage_dict.get("completion_tokens", 0))

        # Cost per 1M tokens, so divide by 1,000,000
        input_cost = (prompt_tokens * pricing["input"]) / 1_000_000
        output_cost = (completion_tokens * pricing["output"]) / 1_000_000

        return input_cost + output_cost

    def generate(self, chinese: str, pinyin: str) -> FieldGenerationResult:
        import json

        # Create input messages for Responses API
        input_messages = [
            {"role": "system", "content": self.prompt},
            {
                "role": "user",
                "content": json.dumps({"character": chinese, "pinyin": pinyin}, ensure_ascii=False),
            },
        ]
        
        kwargs: Dict[str, Any] = {
            "model": self.model,
            "input": input_messages,
        }
        
        if self.temperature is not None:
            kwargs["temperature"] = self.temperature
            
        # Add web search tool if requested
        if self.use_web_search:
            kwargs["tools"] = [{"type": "web_search_preview"}]

        response = self.client.responses.create(**kwargs)
        content = response.output_text
        data = json.loads(content)

        # Extract token usage and calculate cost
        usage_dict = response.usage.dict() if response.usage else {}
        cost = self._calculate_cost(usage_dict)

        # OpenAI Responses API uses 'input_tokens' and 'output_tokens'
        prompt_tokens = usage_dict.get("input_tokens", usage_dict.get("prompt_tokens", 0))
        completion_tokens = usage_dict.get("output_tokens", usage_dict.get("completion_tokens", 0))

        token_usage = TokenUsage(
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=usage_dict.get("total_tokens", 0),
            cost_usd=cost,
        )

        return FieldGenerationResult(
            structural_decomposition=data.get("structural_decomposition_html"),
            etymology=data.get("etymology_html"),
            token_usage=token_usage,
        )
